{
 "cells": [
  {
   "cell_type": "code",
   "id": "7d994fe05e89ab79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T17:05:38.994468Z",
     "start_time": "2025-11-09T17:05:38.979068Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-09T16:06:02.280961Z",
     "start_time": "2025-11-09T16:06:01.681460Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 1,
   "source": "df = pd.read_csv(\"P1/P1_S6/softpriors_counts_and_times_per_channel_filtered.csv\")",
   "id": "initial_id"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T16:06:12.137894Z",
     "start_time": "2025-11-09T16:06:12.107490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_spike_times(x):\n",
    "    if pd.isna(x):\n",
    "        return []               # missing value\n",
    "    elif isinstance(x, str):\n",
    "        return ast.literal_eval(x)  # stringified list\n",
    "    elif isinstance(x, (int, float)):\n",
    "        return [x]              # single spike\n",
    "    elif isinstance(x, list):\n",
    "        return x                # already a list\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown type: {type(x)}\")\n",
    "\n",
    "# Apply to all time columns\n",
    "for col in [\"p_spike_1.0_times\", \"p_poly_1.0_times\", \"p_sw_1.0_times\"]:\n",
    "    df[col] = df[col].apply(parse_spike_times)"
   ],
   "id": "3a2657645b28bf85",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T16:06:15.850658Z",
     "start_time": "2025-11-09T16:06:15.843118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def merge_spikes(row):\n",
    "    total_count = row[\"p_spike_1.0_count\"] + row[\"p_poly_1.0_count\"] + row[\"p_sw_1.0_count\"]\n",
    "\n",
    "    all_spike_times = row[\"p_spike_1.0_times\"] + row[\"p_poly_1.0_times\"] + row[\"p_sw_1.0_times\"]\n",
    "    all_spike_types = (\n",
    "        [\"p_spike\"] * len(row[\"p_spike_1.0_times\"]) +\n",
    "        [\"p_poly\"] * len(row[\"p_poly_1.0_times\"]) +\n",
    "        [\"p_sw\"] * len(row[\"p_sw_1.0_times\"])\n",
    "    )\n",
    "\n",
    "   # Sort spikes *within* this region by time\n",
    "    if len(all_spike_times) > 0:\n",
    "        sorted_pairs = sorted(zip(all_spike_times, all_spike_types), key=lambda x: x[0])\n",
    "        all_spike_times, all_spike_types = zip(*sorted_pairs)\n",
    "    else:\n",
    "        all_spike_times, all_spike_types = [], []\n",
    "\n",
    "    return pd.Series({\n",
    "        \"total_spike_count\": total_count,\n",
    "        \"all_spike_times\": list(all_spike_times),\n",
    "        \"all_spike_types\": list(all_spike_types)\n",
    "    })"
   ],
   "id": "121bfad8d3cfd3d5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T16:07:55.769441Z",
     "start_time": "2025-11-09T16:07:55.734829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "merged_spikes = df.apply(merge_spikes, axis=1)\n",
    "df[\"total_spike_count\"] = merged_spikes[\"total_spike_count\"]\n",
    "df[\"all_spike_times\"] = merged_spikes[\"all_spike_times\"]\n",
    "df[\"all_spike_types\"] = merged_spikes[\"all_spike_types\"]\n",
    "merged_spikes.to_csv(\"P1/P1_S6/merged_spikes.csv\")"
   ],
   "id": "3d352c5492d638c6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T17:39:10.573347Z",
     "start_time": "2025-11-09T17:39:10.502130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spikes_df = pd.read_csv('P1/P1_S6/merged_spikes.csv')          # your spike data\n",
    "coords_df = pd.read_csv('P1/P1_S6/mni_coordinates.csv')     # channel -> MNI mapping\n",
    "\n",
    "# If MNI coordinates are strings in coordinates.csv, convert them to lists\n",
    "coords_df['MNI'] = coords_df['MNI'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Create a dictionary for fast lookup: channel name -> MNI\n",
    "mni_dict = dict(zip(coords_df['Channel'], coords_df['MNI']))\n",
    "\n",
    "# Function to get MNI coordinates for each electrode in a channel pair\n",
    "def get_mni_coords(channel_pair):\n",
    "    ch1, ch2 = channel_pair.split('-')  # split \"LA1-LA2\" into [\"LA1\",\"LA2\"]\n",
    "    mni1 = mni_dict.get(ch1, None)      # lookup MNI coordinates\n",
    "    mni2 = mni_dict.get(ch2, None)\n",
    "    return pd.Series([mni1, mni2])\n",
    "\n",
    "# Apply function to create two new columns next to 'Channels'\n",
    "spikes_df[['MNI Channel 1', 'MNI Channel 2']] = spikes_df['Channels'].apply(get_mni_coords)\n",
    "\n",
    "# Optional: reorder columns so the MNI columns are right after 'Channels'\n",
    "cols = spikes_df.columns.tolist()\n",
    "channels_index = cols.index('Channels')\n",
    "new_order = cols[:channels_index+1] + ['MNI Channel 1', 'MNI Channel 2'] + cols[channels_index+1:-2]\n",
    "spikes_df = spikes_df[new_order]\n",
    "\n",
    "# Save the augmented CSV\n",
    "spikes_df.to_csv('spikes_with_mni.csv', index=False)"
   ],
   "id": "29e6392e591fcb9d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0   Channels               MNI Channel 1  \\\n",
      "0           0    LA1-LA2  [-18.631, -3.602, -24.235]   \n",
      "1           1  LA10-LA11  [-53.653, -3.209, -26.017]   \n",
      "2           2  LA11-LA12   [-57.567, -3.09, -26.314]   \n",
      "3           3    LA2-LA3  [-22.428, -3.563, -24.289]   \n",
      "4           4    LA3-LA4   [-26.25, -3.548, -24.342]   \n",
      "\n",
      "                MNI Channel 2  total_spike_count  \\\n",
      "0  [-22.428, -3.563, -24.289]                 10   \n",
      "1   [-57.567, -3.09, -26.314]                 14   \n",
      "2   [-61.42, -2.926, -26.466]                 17   \n",
      "3   [-26.25, -3.548, -24.342]                 17   \n",
      "4  [-30.096, -3.545, -24.449]                 13   \n",
      "\n",
      "                                     all_spike_times  \\\n",
      "0  [445.78, 1992.76, 2007.49, 2011.7, 2077.905, 3...   \n",
      "1  [444.84, 1996.3, 3513.75, 3613.995, 3625.58, 3...   \n",
      "2  [3496.66, 3513.755, 3614.005, 4304.55, 4322.59...   \n",
      "3  [1091.765, 2009.38, 2501.5, 2943.875, 3252.86,...   \n",
      "4  [2538.88, 3615.435, 3631.22, 4304.255, 4969.26...   \n",
      "\n",
      "                                     all_spike_types  \n",
      "0  ['p_spike', 'p_sw', 'p_spike', 'p_sw', 'p_spik...  \n",
      "1  ['p_sw', 'p_sw', 'p_spike', 'p_spike', 'p_spik...  \n",
      "2  ['p_sw', 'p_sw', 'p_sw', 'p_sw', 'p_sw', 'p_sw...  \n",
      "3  ['p_spike', 'p_sw', 'p_sw', 'p_sw', 'p_sw', 'p...  \n",
      "4  ['p_sw', 'p_spike', 'p_sw', 'p_spike', 'p_sw',...  \n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T10:16:58.568659Z",
     "start_time": "2025-11-10T10:16:58.509368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mni_diff_df = pd.read_csv(\"P1/P1_S6/spikes_with_mni.csv\")\n",
    "\n",
    "mni_diff_df['MNI Channel 1'] = mni_diff_df['MNI Channel 1'].apply(ast.literal_eval)\n",
    "mni_diff_df['MNI Channel 2'] = mni_diff_df['MNI Channel 2'].apply(ast.literal_eval)\n",
    "\n",
    "# Extract x, y, z from each column\n",
    "mni_diff_df[['x1', 'y1', 'z1']] = pd.DataFrame(mni_diff_df['MNI Channel 1'].tolist(), index=mni_diff_df.index)\n",
    "mni_diff_df[['x2', 'y2', 'z2']] = pd.DataFrame(mni_diff_df['MNI Channel 2'].tolist(), index=mni_diff_df.index)\n",
    "\n",
    "# Compute differences\n",
    "mni_diff_df['dx'] = mni_diff_df['x2'] - mni_diff_df['x1']\n",
    "mni_diff_df['dy'] = mni_diff_df['y2'] - mni_diff_df['y1']\n",
    "mni_diff_df['dz'] = mni_diff_df['z2'] - mni_diff_df['z1']\n",
    "\n",
    "mni_diff_df['distance'] = ((mni_diff_df['dx']**2 + mni_diff_df['dy']**2 + mni_diff_df['dz']**2)**0.5)\n",
    "\n",
    "mni_diff_df.to_csv('P1/P1_S6/mni_diff_with_mni.csv')"
   ],
   "id": "2170d0be17f4b91b",
   "outputs": [],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
